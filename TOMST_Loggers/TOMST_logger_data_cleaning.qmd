---
title: "TOMST_logger_data_cleaning"
format: html
editor: visual
creator: TOURIERE Mathéo
date: today
---

## TOMST loggers data cleaning code

Installing all the packages requiered to run the code

```{r install packages}

install.packages("tidyverse")
install.packages("lubridate")
install.packages("dataDownloader")
install.packages("purrrlyr")
install.packages("readxl")
install.packages("fs")
install.packages("purrr")
install.packages("readr")
install.packages("ggplot2")
install.packages("lme4")
install.packages("stargazer")
install.packages("myClim")
```

Load all the packages needed

```{r load_packages}

library(tidyverse)
library(lubridate)
# library(dataDownloader)
library(purrrlyr)
library(readxl)
library(readr)
library(tidyverse)
library(fs)
library(purrr)
library(readr)
library(ggplot2)
library(lme4)
library(stargazer)
library(emmeans)
library(see)
library(svglite)
library(officer)
library(lmerTest)
library(officer)
library(myClim)
```

Importing metadata from the TOMST loggers files

```{r data import}
metadata <- read_delim("Lygra_2024_04_30_metadata.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)


```

```{r}

# Trouver les colonnes "loggerID" et "plotID"
loggerIDColumn <- which(names(metadata) == "loggerID")
plotIDColumn <- which(names(metadata) == "plotID")

# Trier les données par ordre croissant selon la colonne "loggerID"
metadata <- metadata |> 
  arrange(metadata[, loggerIDColumn])

# Sélectionner un dossier à traiter
folder_path <- "C:/Users/Touriere/Desktop/GEN/4A/SIRD/Data/Lygra30042024/DURIN_Lygra_microclimate_2024_04_30_all"      #choose.dir()'

# Lister les fichiers dans le dossier
file_list <- list.files(folder_path)

# Créer un data frame pour stocker les chemins des fichiers, les localités et les formats de données
path_data <- data.frame(
  path = file.path(folder_path, file_list),
  
  locality_id  = as.numeric(substr(file_list, 6, 13)), # Extraire les chiffres du nom du fichier
  data_format = "TOMST" # Définir le format de données comme "TOMST"
) 

# Créer un data frame pour stocker que les données utiles
complete_data <- data.frame(
  loggerID = path_data$locality)
complete_data <- left_join(complete_data, metadata, by = join_by(loggerID))

localities_data <- data.frame(locality_id = as.character(complete_data$loggerID))
  
# Écrire les données dans un fichier csv
#write_csv(path_data, "chemin_vers_votre_dossier/Path.xlsx", row.names = FALSE)
#write_csv(localities_data, "chemin_vers_votre_dossier/Localities.xlsx", row.names = FALSE)



# Informer l'utilisateur que le processus est terminé
cat("Traitement terminé avec succès.\n")

```

Importing data

```{r}
tms.m <- mc_read_data(files_table = path_data,
                      localities_table = localities_data,
                      silent = T)

```

```{r}
# clean runs automatically while reading
#tms <- mc_prep_clean(tms.m, silent = T) # clean series

#> Warning in mc_prep_clean(tms.m, silent = T): MyClim object is already cleaned.
#> Repeated cleaning overwrite cleaning informations.
tms.info <- mc_info_clean(tms) # call cleaning log

# crop the time-series
start <- as.POSIXct("2023-04-01", tz = "UTC")
end   <- as.POSIXct("2024-04-30", tz = "UTC")

tms <- mc_prep_crop(tms, start, end)

```

Aggregation

```{r}
# with defaults only convert Raw-format  to Agg-format
tms.ag <- mc_agg(tms.m,fun = NULL, period = NULL)

# aggregate to daily mean, range, coverage, and 95 percentile. 
tms.day <- mc_agg(tms, fun = c("mean", "range", "coverage", "percentile"),
                percentiles = 95, period = "day", min_coverage = 0.95)

# aggregate all time-series, return one value per sensor.
tms.all <- mc_agg(tms, fun = c("mean", "range", "coverage", "percentile"),
                percentiles = 95, period = "all", min_coverage = 0.95)

# aggregate with your custom function. (how many records are below -5°C per month)
tms.all.custom <- mc_agg(tms.out, fun = list(TMS_T3 = "below5"), period = "month",
                         custom_functions = list(below5 = function(x){length(x[x<(-5)])}))
r <- mc_reshape_long(tms.all.custom)
```
